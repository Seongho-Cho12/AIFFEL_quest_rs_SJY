{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08e7e0e-22b9-4036-9459-87ad9a07199c",
   "metadata": {},
   "source": [
    "# Transformer와 비교해 변경이 필요한 부분\n",
    "- 인코더 블록 제거\n",
    "  - GPT-1: 디코더민 사용\n",
    "- 입력 embedding 처리 변경\n",
    "  - word embedding+ positional embedding으로 변경\n",
    "- 디코더 블록 수정\n",
    "  - Masked Self-Attention 적용\n",
    "  - Encoder-Decoder Attention 제거\n",
    "- 디코더 출력 후 Transposed Token Embedding + Softmax로 예측\n",
    "- Loss 계산 방식 변경\n",
    "  - 매 스텝마다 cross entropy(next token prediction loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f320657-8d99-49a3-a884-d74a4b03021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4ea5f-41f8-42ef-a35b-0dde4655a99b",
   "metadata": {},
   "source": [
    "# 1. 데이터 전처리\n",
    "- Q, A를 하나의 시퀸스로 만들기, 구분자로 구분하기\n",
    "- 토크나이즈\n",
    "-  input/target 시퀸스 생성\n",
    "    - Context Window 방식: tokenized 된 시퀸스를 일정한 크기(max_len)의 window로 잘라서, 각 window 마다 다음 토큰 예측을 학습하게 함. \n",
    "    - Input = 첫 토큰부터 N-1번째까지 / Target = 두 번째 토큰부터 N번째까지  \n",
    "-  배치 만들기\n",
    "    - max_len 로 크기 맞추기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68472b55-3dd5-4929-a444-af23bc029996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>잡아야 되는건지 말아야 되는건지 모르겠네.</td>\n",
       "      <td>후회할 거라면 마지막으로 잡는 건 어떨까요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>오늘 짝남 만나는데 옷이 없다.</td>\n",
       "      <td>이 김에 하나 장만하는 건 어떨까요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>건물주가 짱인데</td>\n",
       "      <td>이룰 수 있을 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6648</th>\n",
       "      <td>새 남자가 생겼대</td>\n",
       "      <td>새 사람 만나면 돼요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>필통 두고 옴</td>\n",
       "      <td>빌리면 돼요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "7908   잡아야 되는건지 말아야 되는건지 모르겠네.  후회할 거라면 마지막으로 잡는 건 어떨까요.      1\n",
       "10786        오늘 짝남 만나는데 옷이 없다.      이 김에 하나 장만하는 건 어떨까요.      2\n",
       "117                   건물주가 짱인데              이룰 수 있을 거예요.      0\n",
       "6648                 새 남자가 생겼대              새 사람 만나면 돼요.      1\n",
       "4942                   필통 두고 옴                   빌리면 돼요.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 가져오기\n",
    "path = \"C:/Users/yjneo/AIFFEL_quest_rs/Exploration/Ex07/ChatbotData.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b2126e-61df-4d99-a833-de9a7276267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def preprocess_sentence(sentence):\n",
    "#     # 1. 양쪽 공백 제거\n",
    "#     sentence = sentence.strip()\n",
    "\n",
    "#     # 2. 주요 구두점(?, !, ,)은 띄어쓰기로 분리 (마침표는 제거)\n",
    "#     sentence = re.sub(r\"([?!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "#     # 3. 한글, 영문, 숫자, 주요 구두점(?, !, ,)만 남기고 나머지는 제거\n",
    "#     sentence = re.sub(r\"[^가-힣a-zA-Z0-9?!,]\", \" \", sentence)\n",
    "\n",
    "#     # 4. 여러 공백을 하나로 줄이기\n",
    "#     sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "\n",
    "#     return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1212d7cf-5f4c-47c1-b1df-2323b8bc0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드하고 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions_raw= list(data['Q'])\n",
    "answers_raw = list(data['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163005d7-288c-4b3e-9a48-0f518abfd545",
   "metadata": {},
   "source": [
    "## Q, A를 하나의 시퀸스로 만들기, 구분자로 구분하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb86267e-ae1e-4daa-9f7d-e985341ab8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12시 땡! <delim> 하루가 또 가네요. <delim> 1지망 학교 떨어졌어 <delim> 위로해 드립니다. <delim> 3박4일 놀러가고 싶다 <delim> 여행은 언제나\n"
     ]
    }
   ],
   "source": [
    "# 구분자 정의\n",
    "delimiter = '<delim>'\n",
    "\n",
    "# Q, A를 구분자로 이어붙인 하나의 긴 시퀀스를 만든다\n",
    "long_sequence = ''\n",
    "\n",
    "for question, answer in zip(questions_raw, answers_raw):\n",
    "    # 질문과 답변을 구분자로 이어붙임\n",
    "    pair = f'{question} {delimiter} {answer}'\n",
    "    # 쌓아나가기\n",
    "    if long_sequence:\n",
    "        long_sequence += f' {delimiter} {pair}'\n",
    "    else:\n",
    "        long_sequence = pair\n",
    "\n",
    "# 결과 확인\n",
    "print(long_sequence[:100])  # 앞부분 5자만 미리 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc082dc-7413-4c0a-85ad-05fa6497db92",
   "metadata": {},
   "source": [
    "## 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd449184-0b9e-4745-882c-0f31dcd38aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens after tokenization: 542598\n",
      "[1254, 1255, 40, 1237, 758, 1238, 1237, 1265, 1305, 1306, 1313, 1310, 1314, 1267, 1237, 5, 271, 7, 1237, 223, 1237, 7, 29, 1, 1251, 1237, 1265, 1305, 1306, 1313]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# 1. Tokenizer 학습: 긴 시퀀스들을 기반으로 서브워드 토크나이저 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    long_sequence, target_vocab_size=2**13)\n",
    "\n",
    "\n",
    "# 2. 단어장 크기\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "\n",
    "\n",
    "# 3. 긴 시퀀스 정수 인코딩 (Tokenize)\n",
    "tokenized_ids = tokenizer.encode(long_sequence)\n",
    "\n",
    "print(f\"Total tokens after tokenization: {len(tokenized_ids)}\")\n",
    "print(tokenized_ids[:30])  # 앞쪽 일부 토큰 확인\n",
    "\n",
    "\n",
    "#\n",
    "# #시작토큰과 종료토큰에 고유한 정수 부여\n",
    "# START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "# VOCAB_SIZE = tokenizer.vocab_size + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17962a05-7012-43c4-9e0d-81d2f64c9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 패딩, 샘플 제거 함수\n",
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "# print(MAX_LENGTH)\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # # 최대 길이 21으로 모든 데이터셋을 패딩\n",
    "  # tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "  #     tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  # tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "  #     tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a926d22-990f-49fe-a2a0-f02ae7677378",
   "metadata": {},
   "source": [
    "## input/target 시퀸스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0729786-2d5e-49ea-8214-4cd61de094a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 생성된 context windows 개수: 2118\n",
      "첫 번째 input: [1254, 1255, 40, 1237, 758, 1238, 1237, 1265, 1305, 1306]\n",
      "첫 번째 target: [1255, 40, 1237, 758, 1238, 1237, 1265, 1305, 1306, 1313]\n"
     ]
    }
   ],
   "source": [
    "max_len = 512\n",
    "# context window 방식 함수\n",
    "def create_context_windows(tokenized_ids, max_len, stride=None):\n",
    "    \"\"\"\n",
    "    긴 tokenized_ids를 context window 방식으로 자르는 함수\n",
    "    Args:\n",
    "        tokenized_ids: 전체 긴 토큰 ID 리스트\n",
    "        max_len: window 크기\n",
    "        stride: 슬라이딩할 간격 (기본은 max_len과 같음 = overlap 없음)\n",
    "    Returns:\n",
    "        input_ids_list, target_ids_list\n",
    "    \"\"\"\n",
    "    if stride is None:\n",
    "        stride = max_len  # 겹침 없이 바로 다음 window로 넘어감\n",
    "\n",
    "    input_ids_list = []\n",
    "    target_ids_list = []\n",
    "\n",
    "    for start_idx in range(0, len(tokenized_ids) - max_len, stride):\n",
    "        end_idx = start_idx + max_len\n",
    "\n",
    "        input_ids = tokenized_ids[start_idx:end_idx]\n",
    "        target_ids = tokenized_ids[start_idx + 1:end_idx + 1]\n",
    "\n",
    "        input_ids_list.append(input_ids)\n",
    "        target_ids_list.append(target_ids)\n",
    "\n",
    "    return input_ids_list, target_ids_list\n",
    "\n",
    "# 사용 예시\n",
    "input_sequences, target_sequences = create_context_windows(\n",
    "    tokenized_ids,\n",
    "    max_len=512,\n",
    "    stride=256  # 절반씩 겹치게 자르는 예시\n",
    ")\n",
    "\n",
    "print(f\"총 생성된 context windows 개수: {len(input_sequences)}\")\n",
    "print(f\"첫 번째 input: {input_sequences[0][:10]}\")  # 앞쪽 10개 토큰\n",
    "print(f\"첫 번째 target: {target_sequences[0][:10]}\")\n",
    "# print(input_sequences.shape)\n",
    "# print(output_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145f261-b155-4ef8-b5b7-b72f17448f7e",
   "metadata": {},
   "source": [
    "## 배치 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f735710-8d5b-4d30-adcb-07ebbdfdb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Input Shape: (32, 512)\n",
      "Batch Target Shape: (32, 512)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_batches(input_sequences, target_sequences, batch_size):\n",
    "    \"\"\"\n",
    "    input/target 시퀀스를 batch로 묶어주는 함수\n",
    "    Args:\n",
    "        input_sequences: (list) 자른 input 시퀀스 리스트\n",
    "        target_sequences: (list) 자른 target 시퀀스 리스트\n",
    "        batch_size: (int) 배치 크기\n",
    "    Returns:\n",
    "        batched_dataset: (tf.data.Dataset) 배치가 적용된 데이터셋\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 리스트를 텐서로 변환\n",
    "    inputs = tf.constant(input_sequences, dtype=tf.int32)\n",
    "    targets = tf.constant(target_sequences, dtype=tf.int32)\n",
    "\n",
    "    # 2. Dataset 객체로 변환\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "\n",
    "    # 3. 셔플(선택) + 배치\n",
    "    dataset = dataset.shuffle(buffer_size=len(input_sequences))  # 선택사항\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# 예시 사용법\n",
    "batch_size = 32\n",
    "batched_dataset = create_batches(input_sequences, target_sequences, batch_size)\n",
    "\n",
    "# 확인\n",
    "for batch_inputs, batch_targets in batched_dataset.take(1):\n",
    "    print(\"Batch Input Shape:\", batch_inputs.shape)\n",
    "    print(\"Batch Target Shape:\", batch_targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba11b46-a83b-4489-86cb-ac3bbbf9c949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c05637f9-8e4d-47d8-8834-05183c3e20d1",
   "metadata": {},
   "source": [
    "# 2. 입력 블록 \n",
    "- 입력 embedding 처리 변경\n",
    "- word embedding+ positional embedding으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33f930c1-eb21-4999-a203-552b1ed85201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class GPTInputEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_len):\n",
    "        super(GPTInputEmbedding, self).__init__()\n",
    "        self.token_embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = tf.keras.layers.Embedding(max_len, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch_size, seq_len) 정수 인코딩된 입력 시퀀스\n",
    "        Returns:\n",
    "            embeddings: (batch_size, seq_len, d_model) 토큰 + 포지션 임베딩 합쳐진 결과\n",
    "        \"\"\"\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 1. Token Embedding\n",
    "        token_emb = self.token_embedding(x)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # 2. Position Embedding\n",
    "        positions = tf.range(start=0, limit=seq_len, delta=1)\n",
    "        positions = self.position_embedding(positions)  # (seq_len, d_model)\n",
    "        positions = tf.expand_dims(positions, axis=0)  # (1, seq_len, d_model)로 맞춰줌\n",
    "\n",
    "        # 3. Token Embedding + Position Embedding\n",
    "        embeddings = token_emb + positions  # broadcasting으로 합쳐짐\n",
    "\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a986117-2298-41f9-be60-108a3652f0bf",
   "metadata": {},
   "source": [
    "## embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0387b22b-3a50-4e26-8d28-e9fa3753a318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output shape: (32, 512, 768)\n"
     ]
    }
   ],
   "source": [
    "# 세팅\n",
    "vocab_size = VOCAB_SIZE   # 아까 tokenizer vocab size\n",
    "d_model = 768             # GPT-1은 hidden size 768\n",
    "max_len = 512             # 최대 시퀀스 길이\n",
    "\n",
    "# 레이어 만들기\n",
    "input_embedder = GPTInputEmbedding(vocab_size, d_model, max_len)\n",
    "\n",
    "# input 시퀀스 예시 (batch_size=2, seq_len=10)\n",
    "sample_input = tf.constant([[5, 20, 15, 47, 2, 0, 0, 0, 0, 0],\n",
    "                            [7, 18, 13, 49, 4, 3, 0, 0, 0, 0]])\n",
    "\n",
    "# 임베딩 결과\n",
    "embeddings = input_embedder(batch_inputs)\n",
    "\n",
    "print(\"Embedding output shape:\", embeddings.shape)\n",
    "# (batch_size=2, seq_len=10, d_model=768)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff5503-1276-4416-a02e-aefc0c080f9c",
   "metadata": {},
   "source": [
    "# 3. GPT 모델 구성\n",
    "- - 디코더 블록 수정\n",
    "  - Masked Self-Attention 적용\n",
    "  - Encoder-Decoder Attention 제거\n",
    "- Transformer Decoder를 12개 쌓는다. \n",
    "- model.summary\n",
    "- model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a4720-979c-4af7-ba26-83c940015ce6",
   "metadata": {},
   "source": [
    "## decoder layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3881f365-1604-4950-b9c8-ccbf04235911",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, query, key, value, mask):\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "981a760f-9486-40fc-b27a-65dc4afa14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        # ✅ tf.Tensor 타입인 mask 처리\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "175092ce-50de-47d2-bfa4-557d3efc26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "# 현재까지 본 정보까지만 attention \n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)  # (seq_len, seq_len)\n",
    "    mask = tf.expand_dims(mask, axis=0)                                # (1, seq_len, seq_len)\n",
    "    mask = tf.expand_dims(mask, axis=1)                                # (1, 1, seq_len, seq_len)\n",
    "    return mask  # broadcasting은 알아서 이뤄짐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682a0a9-6a3c-4897-b899-47203f2e8779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b7071e9-b594-41e3-ad4f-f44074d7cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")  # (batch_size, seq_len, d_model)\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "    # 1. Masked Multi-Head Self Attention\n",
    "    attn_output = MultiHeadAttention(d_model, num_heads, name=\"masked_attention\")(inputs, inputs, inputs, look_ahead_mask)\n",
    "    attn_output = tf.keras.layers.Dropout(rate=dropout)(attn_output)\n",
    "    out1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)  # Add & Norm\n",
    "\n",
    "    # 2. Position-wise Feed Forward Network\n",
    "    ffn_output = tf.keras.layers.Dense(dff, activation='relu')(out1)\n",
    "    ffn_output = tf.keras.layers.Dense(d_model)(ffn_output)\n",
    "    ffn_output = tf.keras.layers.Dropout(rate=dropout)(ffn_output)\n",
    "    out2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)  # Add & Norm\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, look_ahead_mask],\n",
    "        outputs=out2,\n",
    "        name=name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e1e0fe-1286-4cbf-bac1-2fbd51abd94d",
   "metadata": {},
   "source": [
    "## decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae90d364-c44a-4fb7-8d4a-09aa1825d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(num_layers, dff, d_model, num_heads, dropout, name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name='inputs')  # Embedding된 입력\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "    outputs = inputs  # 초기값은 embedding 결과\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "            dropout=dropout, name=f'decoder_layer_{i}'\n",
    "        )([outputs, look_ahead_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, look_ahead_mask],\n",
    "        outputs=outputs,\n",
    "        name=name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ed983-bf59-4622-8d70-c84d4cb1bb2c",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f63dbae8-4459-4e34-b718-0d34fe8aee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_gpt1_model(vocab_size, num_layers, dff, d_model, num_heads, max_len, dropout=0.1):\n",
    "    input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name='input_ids')  # (batch_size, seq_len)\n",
    "\n",
    "    # Embedding\n",
    "    input_embedder = GPTInputEmbedding(vocab_size, d_model, max_len)\n",
    "    embedded_inputs = input_embedder(input_ids)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "    # Look-ahead mask (Lambda로 생성)\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask,\n",
    "        output_shape=(1, None, None),  # (batch, 1, seq_len, seq_len)\n",
    "        name='look_ahead_mask'\n",
    "    )(input_ids)\n",
    "\n",
    "    # 디코더 통과\n",
    "    decoder_model = decoder(\n",
    "        num_layers=num_layers,\n",
    "        dff=dff,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    decoder_outputs = decoder_model([embedded_inputs, look_ahead_mask])\n",
    "\n",
    "    # Final Linear Projection + Softmax\n",
    "    lm_logits = tf.keras.layers.Dense(vocab_size, name=\"lm_head\")(decoder_outputs)\n",
    "    probs = tf.keras.layers.Softmax(axis=-1, name=\"softmax_output\")(lm_logits)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_ids, outputs=probs, name=\"gpt1_model\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9345d18-ba93-4c2e-920e-d652b5a67c76",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c86ee6d4-252d-4a90-87a2-764c938db7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt1_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt1_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gpt_input_embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,515,264</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPTInputEmbedding</span>)           │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ look_ahead_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">85,054,464</span> │ gpt_input_embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ look_ahead_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lm_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1461</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,123,509</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ softmax_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1461</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lm_head[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gpt_input_embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │       \u001b[38;5;34m1,515,264\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mGPTInputEmbedding\u001b[0m)           │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ look_ahead_mask (\u001b[38;5;33mLambda\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ input_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │      \u001b[38;5;34m85,054,464\u001b[0m │ gpt_input_embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ look_ahead_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lm_head (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1461\u001b[0m)        │       \u001b[38;5;34m1,123,509\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ softmax_output (\u001b[38;5;33mSoftmax\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1461\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ lm_head[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,693,237</span> (334.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m87,693,237\u001b[0m (334.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">87,693,237</span> (334.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m87,693,237\u001b[0m (334.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 세팅\n",
    "vocab_size = VOCAB_SIZE  # 네가 만든 tokenizer vocab size\n",
    "d_model = 768\n",
    "dff = 3072   # position-wise feed-forward hidden size\n",
    "num_heads = 12  # 멀티 어텐션 헤드 12개\n",
    "num_layers = 12 # 디코더 레이어 12개 \n",
    "max_len = 512\n",
    "\n",
    "# 모델 만들기\n",
    "gpt1_model = create_gpt1_model(\n",
    "    vocab_size=vocab_size,\n",
    "    num_layers=num_layers,\n",
    "    dff=dff,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    max_len=max_len,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "# 모델 구조 보기\n",
    "gpt1_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2bf80e-dbae-4c62-bc6e-1e02b780bdd6",
   "metadata": {},
   "source": [
    "# 4. 모델 컴파일, 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f58c05-0fa1-4f82-b901-2a4d170221e1",
   "metadata": {},
   "source": [
    "## 손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a515163-f226-4462-b074-7fd14d5006b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=False, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec14fb9-1f01-4d58-a247-6907a076a036",
   "metadata": {},
   "source": [
    "## 커스텀된 학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acae133b-f4cb-4c08-9027-2a350eaefde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc8798-67c4-46aa-9110-c4f415b0605f",
   "metadata": {},
   "source": [
    "## 메트릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4cb6e57-34ed-4dd8-85ed-9c9b5521880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41817e68-16e3-4dce-a530-b41fb738fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Learning Rate 스케줄러 만들기\n",
    "learning_rate = CustomSchedule(d_model=768)\n",
    "\n",
    "# 2. Optimizer 설정 (Adam)\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate,  # 🎯 여기 스케줄 객체 넣음\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-8\n",
    ")\n",
    "\n",
    "# 3. Loss 함수 설정\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "\n",
    "# 4. 모델 컴파일\n",
    "gpt1_model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01bd742f-c904-43ed-ab2e-095a3033b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#콜백 정의 \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f5af19e-b88d-4b45-a574-f34901f4d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(batch_size, seq_len):\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)  # (seq_len, seq_len)\n",
    "    look_ahead_mask = tf.expand_dims(look_ahead_mask, axis=0)                      # (1, seq_len, seq_len)\n",
    "    look_ahead_mask = tf.tile(look_ahead_mask, [batch_size, 1, 1])                  # (batch_size, seq_len, seq_len)\n",
    "    look_ahead_mask = tf.expand_dims(look_ahead_mask, axis=1)                      # (batch_size, 1, seq_len, seq_len)\n",
    "    return look_ahead_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b634ce20-7621-4b68-a07b-5ee491f5887e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m  3/120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:49:50\u001b[0m 87s/step - accuracy: 0.0022 - loss: 7.3011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py\", line 694, in write\n",
      "    self._schedule_flush()\n",
      "  File \"C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py\", line 590, in _schedule_flush\n",
      "    self.pub_thread.schedule(_schedule_in_thread)\n",
      "  File \"C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\ipykernel\\iostream.py\", line 267, in schedule\n",
      "    self._event_pipe.send(b\"\")\n",
      "  File \"C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\zmq\\sugar\\socket.py\", line 701, in send\n",
      "    return super().send(data, flags=flags, copy=copy, track=track)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"_zmq.py\", line 1092, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1140, in zmq.backend.cython._zmq.Socket.send\n",
      "  File \"_zmq.py\", line 1339, in zmq.backend.cython._zmq._send_copy\n",
      "  File \"_zmq.py\", line 160, in zmq.backend.cython._zmq._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 학습\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m gpt1_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     20\u001b[0m     input_sequences,\n\u001b[0;32m     21\u001b[0m     target_sequences,\n\u001b[0;32m     22\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m     23\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[0;32m     24\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[0;32m     25\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[0;32m     26\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1694\u001b[0m   )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 데이터 준비\n",
    "input_sequences = tf.convert_to_tensor(input_sequences, dtype=tf.int32)\n",
    "target_sequences = tf.convert_to_tensor(target_sequences, dtype=tf.int32)\n",
    "\n",
    "batch_size = tf.shape(input_sequences)[0]  # 1906\n",
    "seq_len = tf.shape(input_sequences)[1]     # 512\n",
    "\n",
    "# Look Ahead Mask 만들기\n",
    "look_ahead_mask = create_look_ahead_mask(batch_size, seq_len)\n",
    "\n",
    "# x를 리스트로\n",
    "x = [input_sequences, look_ahead_mask]\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "# 학습\n",
    "gpt1_model.fit(\n",
    "    input_sequences,\n",
    "    target_sequences,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18bbc581-739e-41a3-a7ae-47c1fa3671b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# 설치된 GPU 디바이스 확인\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2757335-704d-4a67-aa61-a0128065bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "# 파이썬 버전 확인\n",
    "# python --version    #3.11.9\n",
    "#tensorflow 버전 확인\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)   # 2.19.0\n",
    "\n",
    "\n",
    "# # 설치된 CUDA 버전 확인\n",
    "# nvcc --version\n",
    "# nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e5404-b1f3-41cc-ad46-c778f11ae8fd",
   "metadata": {},
   "source": [
    "# 모델 확인\n",
    "- 입력에 따른 출력이 생성되는지 확인\n",
    "- 출력 결과물의 수준에 상관없이 모델이 정상적으로 동작하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2a63e-abaf-4eec-ba42-0673438d53e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
