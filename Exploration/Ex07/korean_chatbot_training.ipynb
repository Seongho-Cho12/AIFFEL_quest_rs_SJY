{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3816c2-5d61-4f4f-a77e-cd42366ff78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fa3cac-3fd1-47fe-8884-c4048320a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c65a52-82a0-404f-9802-894dc5e29f12",
   "metadata": {},
   "source": [
    "# 1. 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42918f2f-d728-420f-9bb5-b8f5a08c1df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5088</th>\n",
       "      <td>향수 뿌려도 될라나</td>\n",
       "      <td>향기 나면 좋아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>클럽가고 싶은데 말하고 갈까</td>\n",
       "      <td>말하고 가거나 같이 가보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>후련해</td>\n",
       "      <td>후련하다니 다행이에요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>연예인 되면 피곤하겠지?</td>\n",
       "      <td>아무래도 사생활이 적으니까요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>머리 깎아야겠다.</td>\n",
       "      <td>예쁘게 깎아요!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Q                 A  label\n",
       "5088       향수 뿌려도 될라나        향기 나면 좋아요.      0\n",
       "4784  클럽가고 싶은데 말하고 갈까  말하고 가거나 같이 가보세요.      0\n",
       "8790              후련해      후련하다니 다행이에요.      1\n",
       "3227    연예인 되면 피곤하겠지?  아무래도 사생활이 적으니까요.      0\n",
       "1584        머리 깎아야겠다.          예쁘게 깎아요!      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/yjneo/AIFFEL_quest_rs/Exploration/Ex07/ChatbotData.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a5b11e-70e1-4383-955c-5b7de26ac371",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655e2ae1-6ac9-465a-9bb3-7aa4f1e1db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # 1. 양쪽 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 2. 주요 구두점(?, !, ,)은 띄어쓰기로 분리 (마침표는 제거)\n",
    "    sentence = re.sub(r\"([?!,])\", r\" \\1 \", sentence)\n",
    "\n",
    "    # 3. 한글, 영문, 숫자, 주요 구두점(?, !, ,)만 남기고 나머지는 제거\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z0-9?!,]\", \" \", sentence)\n",
    "\n",
    "    # 4. 여러 공백을 하나로 줄이기\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence).strip()\n",
    "\n",
    "    return sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39fca7d-be0f-48b5-9a78-45e2c80d85c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 질문을 questions, 답변을 answers에 저장합니다.\n",
    "\n",
    "questions_raw= list(data['Q'])\n",
    "answers_raw = list(data['A'])\n",
    "print('전체 샘플 수 :', len(questions_raw))\n",
    "print('전체 샘플 수 :', len(answers_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f57ba5-6469-4183-b4e1-3ee561aabc52",
   "metadata": {},
   "source": [
    "### 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84a301-58db-4463-8e64-7cddddbd11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2bf04d5-537c-45f4-97e3-026cec864583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "questions = [preprocess_sentence(sentence) for sentence in questions_raw]\n",
    "answers = [preprocess_sentence(sentence) for sentence in answers_raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf2592-ff68-429f-a3b0-0cc3685f80ca",
   "metadata": {},
   "source": [
    "### 전처리 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0240333e-96cc-45f4-8bd5-3bd4c7c3e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: 12시 땡!  →  12시 땡 !\n",
      "A1: 하루가 또 가네요.  →  하루가 또 가네요\n",
      "\n",
      "Q2: 1지망 학교 떨어졌어  →  1지망 학교 떨어졌어\n",
      "A2: 위로해 드립니다.  →  위로해 드립니다\n",
      "\n",
      "Q3: 3박4일 놀러가고 싶다  →  3박4일 놀러가고 싶다\n",
      "A3: 여행은 언제나 좋죠.  →  여행은 언제나 좋죠\n",
      "\n",
      "Q4: 3박4일 정도 놀러가고 싶다  →  3박4일 정도 놀러가고 싶다\n",
      "A4: 여행은 언제나 좋죠.  →  여행은 언제나 좋죠\n",
      "\n",
      "Q5: PPL 심하네  →  PPL 심하네\n",
      "A5: 눈살이 찌푸려지죠.  →  눈살이 찌푸려지죠\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"Q{i+1}: {questions_raw[i]}  →  {questions[i]}\")\n",
    "    print(f\"A{i+1}: {answers_raw[i]}  →  {answers[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397dc647-b060-4dcf-a934-5d1edfaea59b",
   "metadata": {},
   "source": [
    "# 3. SubwordTextEncoder 사용하기\n",
    "- 내부 단어 토크나이저인 SubwordTextEncoder를 사용\n",
    "- 단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩\n",
    "- 각 문장을 토큰화하고 문장의 시작과 끝에 START_TOKEN, END_TOKEN을 추가\n",
    "- 최대 길이 MAX_LEN 지정, 최대 길이를 넘는 문장 필터링\n",
    "- 최대 길이보다 짧은 문장은 맞춰서 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553af8e-d1e8-4dc4-9db2-af49d85e9ff6",
   "metadata": {},
   "source": [
    "## 단어장 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d521e9-7ebd-452d-8fa1-2381af3b3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size =2**13)\n",
    "#시작토큰과 종료토큰에 고유한 정수 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073e5520-82c4-4f8d-a7f3-6c5e452346b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8183]\n",
      "END_TOKEN의 번호 : [8184]\n",
      "8185\n"
     ]
    }
   ],
   "source": [
    "#단어장 크기 +2\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0ec8e-e1f8-4ce5-861d-6b0ddcfb85ed",
   "metadata": {},
   "source": [
    "## 정수 인코딩, 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc2936-0ae0-4c18-a750-6234cc343798",
   "metadata": {},
   "source": [
    "### 정수 인코딩, 패딩, 샘플 제거 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4111e53-b43a-407f-9d55-a15fc098ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "# print(MAX_LENGTH)\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 21 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 21으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da3836-f2c3-4e84-ab87-9d51e5034bb9",
   "metadata": {},
   "source": [
    "### 함수 적용, 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c28e8b9-e4cb-4981-92e8-d66d4921af23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11823, 40)\n",
      "(11823, 40)\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "# ✅ numpy 배열로 변환 (모든 샘플이 MAX_LENGTH로 맞춰져야 함)\n",
    "questions = np.array(questions, dtype=np.int32)\n",
    "answers = np.array(answers, dtype=np.int32)\n",
    "\n",
    "print(questions.shape)  # (전체 샘플 수, MAX_LENGTH)\n",
    "print(answers.shape)    # (전체 샘플 수, MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bc435da-e808-435c-9019-227480f4d4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8183 7922 4210 3061   39 8184    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8183 3843   73 7901 8184    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# 0번 샘플을 임의로 출력\n",
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbcce2c-3719-4986-95ac-25ecb2c598de",
   "metadata": {},
   "source": [
    "##  인코더와 디코더의 입력, 레이블 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "247bcdc6-abad-4133-8834-a9cc1a270906",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# questions = np.array(questions, dtype=np.int32)\n",
    "# answers = np.array(answers, dtype=np.int32)\n",
    "# # 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# # 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     {\n",
    "#         'inputs': questions,\n",
    "#         'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "#     },\n",
    "#     {\n",
    "#         'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "#     },\n",
    "# ))\n",
    "\n",
    "\n",
    "# dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd46404f-b12d-4670-9bdc-7112aeb86302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n",
      "<dtype: 'int32'>\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# for x, y in dataset.take(1):\n",
    "#     print(x['inputs'].dtype)      # tf.int32\n",
    "#     print(x['dec_inputs'].dtype)  # tf.int32\n",
    "#     print(y['outputs'].dtype)     # tf.int32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d279108-0eaa-4c04-b3f6-7726ac818d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8183 3843   73 7901 8184    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8183 3843   73 7901 8184    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3843   73 7901 8184    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# # 임의의 샘플에 대해서 [:, :-1]과 [:, 1:]이 어떤 의미를 가지는지 테스트해본다.\n",
    "# print(answers[0]) # 기존 샘플\n",
    "# print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "# print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac931f6-186e-4d09-9fb2-082685dc9697",
   "metadata": {},
   "source": [
    "# 4. 모델 구성하기\n",
    "- 인코더 층 함수\n",
    "- 디코더 층 함수\n",
    "- 트랜스포머 함수 정의\n",
    "- 모델 생성\n",
    "- 손실 함수\n",
    "- 커스텀된 학습률\n",
    "- 모델 컴파일\n",
    "- 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea1c81-0201-4e31-a2ac-121e0e8337c3",
   "metadata": {},
   "source": [
    "### 트랜스포머 입력 : 포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01ca431a-382c-498f-b39d-40d74886c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    i = tf.cast(i, tf.float32)  # i도 명확히 float32로 캐스팅\n",
    "    angle_rates = 1.0 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return tf.cast(position, tf.float32) * angle_rates\n",
    "\n",
    "\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        tf.range(position)[:, tf.newaxis],\n",
    "        tf.range(d_model)[tf.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # Tensor 기반으로 재결합\n",
    "    angle_rads = tf.concat([sines, cosines], axis=-1)\n",
    "\n",
    "    # 순서 정렬 (짝수-홀수-짝수-홀수가 되도록)\n",
    "    indices = tf.argsort(tf.range(d_model) % 2 * d_model + tf.range(d_model))\n",
    "    pos_encoding = tf.gather(angle_rads, indices, axis=1)\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if isinstance(inputs, tf.SparseTensor):\n",
    "        inputs = tf.sparse.to_dense(inputs)\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577079f-2b32-4a8e-af41-7c38d869b870",
   "metadata": {},
   "source": [
    "### 스케일드 닷 어텐션, 멀티헤드 어텐션, 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dad37021-b857-425b-bb24-bf17397db322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        # ✅ tf.Tensor 타입인 mask 처리\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b99ed66b-e613-4ee7-a285-64a0a13ece4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, query, key, value, mask):\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f51122b9-e8ce-47e4-bb1c-422a29574ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, key의 문장 길이)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307e3b7-211c-43db-8a7c-762c6a6acbc4",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afbea605-5ebe-4966-a628-df0d66d4305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 셀프 어텐션 (Q = K = V = inputs)\n",
    "  attention = MultiHeadAttention(d_model, num_heads, name=\"attention\")(\n",
    "      inputs, inputs, inputs, padding_mask\n",
    "  )\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결 + 정규화\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드포워드\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결 + 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d758eeb2-eb93-49c0-972b-ab87589ceea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  \n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(1000, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        dff=dff, d_model=d_model, num_heads=num_heads, dropout=dropout, name=f\"encoder_layer_{i}\"\n",
    "    )(inputs=[outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc7c7d-1404-44d1-aced-cdd83039a4ec",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "555d936d-b212-4ebe-a9a6-e193ff3758ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea59d00b-70b3-499a-8db1-f36126a7e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 1. 첫 번째 멀티-헤드 어텐션 (마스크드 셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(d_model, num_heads, name=\"attention_1\")(\n",
    "      inputs, inputs, inputs, look_ahead_mask\n",
    "  )\n",
    "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 2. 두 번째 멀티-헤드 어텐션 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(d_model, num_heads, name=\"attention_2\")(\n",
    "      attention1, enc_outputs, enc_outputs, padding_mask\n",
    "  )\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 3. 포지션 와이즈 피드 포워드\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f2c546d-d729-42af-8769-2f2702f85773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(1000, d_model)(embeddings)  # max_position으로 수정 권장\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "      outputs = decoder_layer(\n",
    "          dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "          dropout=dropout, name=f'decoder_layer_{i}'\n",
    "      )([\n",
    "          outputs,           # 디코더 현재 입력\n",
    "          enc_outputs,       # 인코더 출력\n",
    "          look_ahead_mask,   # 첫 번째 마스크\n",
    "          padding_mask       # 두 번째 마스크\n",
    "  ])\n",
    "\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39bb52-183c-4a5f-8dc9-98cb757b18d5",
   "metadata": {},
   "source": [
    "### 트랜스포머"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a15bd91-a444-47cc-9fe9-b91731921915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더의 패딩 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더의 룩어헤드 마스크\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더의 패딩 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더 출력\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      dff=dff,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )([inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더 출력\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      dff=dff,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(\n",
    "      [dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask]\n",
    "  )\n",
    "\n",
    "  # 출력층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026ff09c-894f-4f42-a394-43880ea8e7aa",
   "metadata": {},
   "source": [
    "### 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b776f4da-2659-4142-b192-2ff4585a1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea65799-053b-482e-b7b9-a755d7919e4b",
   "metadata": {},
   "source": [
    "### 커스텀된 확습률\n",
    "- 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e1a14cc-a7cd-4949-af51-201b562fd6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28d39e80-0726-4546-8ff0-8e781c20968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e548f8a-d26d-469f-8b75-54ecd233a899",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2aa8154e-ade7-42c9-be7a-7d1aa6c20865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yjneo\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ enc_padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,149,568</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n",
       "│                               │                           │                 │ enc_padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ look_ahead_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec_padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,676,928</span> │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ look_ahead_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                               │                           │                 │ dec_padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ outputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8185</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,545</span> │ decoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec_inputs (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ enc_padding_mask (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m3,149,568\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n",
       "│                               │                           │                 │ enc_padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ look_ahead_mask (\u001b[38;5;33mLambda\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dec_padding_mask (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m3,676,928\u001b[0m │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ look_ahead_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                               │                           │                 │ dec_padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ outputs (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8185\u001b[0m)        │       \u001b[38;5;34m2,103,545\u001b[0m │ decoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,930,041</span> (34.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,930,041\u001b[0m (34.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,930,041</span> (34.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,930,041\u001b[0m (34.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd99dd7-8eee-4b11-9f43-1414569ffeba",
   "metadata": {},
   "source": [
    "###  모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1327e88d-3409-4ad0-915b-9224d12f0cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd35b50b-a8f4-408a-a64b-92c29b73a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 반드시 정수형 배열인지 확인\n",
    "# # questions = np.array(questions, dtype=np.int32)\n",
    "# # answers = np.array(answers, dtype=np.int32)\n",
    "# tf.keras.backend.clear_session()  # 모델 세션 초기화 \n",
    "# # 2. Dataset 생성 시, slicing 정확히!\n",
    "# new_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "#     {\n",
    "#         'inputs': questions,\n",
    "#         'dec_inputs': answers[:, :-1]\n",
    "#     },\n",
    "#     {\n",
    "#         'outputs': answers[:, 1:]\n",
    "#     },\n",
    "# ))\n",
    "\n",
    "# # 3. batch, shuffle, prefetch\n",
    "# new_dataset = new_dataset.shuffle(BUFFER_SIZE)\n",
    "# new_dataset = new_dataset.batch(BATCH_SIZE)\n",
    "# new_dataset = new_dataset.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e395e75-fe54-4e2d-a3a4-af0969de3e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: (64, 40)\n",
      "dec_inputs: (64, 39)\n",
      "outputs: (64, 39)\n"
     ]
    }
   ],
   "source": [
    "# for x, y in new_dataset.take(1):\n",
    "#     print(\"inputs:\", x['inputs'].shape)      # ✅ (batch_size, seq_len)\n",
    "#     print(\"dec_inputs:\", x['dec_inputs'].shape)\n",
    "#     print(\"outputs:\", y['outputs'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433796f-f300-470e-a136-4685b771d21b",
   "metadata": {},
   "source": [
    "##  모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d37b6f9d-d5bb-4972-b88f-54d353ed5fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 591ms/step - accuracy: 0.0317 - loss: 0.8910\n",
      "Epoch 2/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 568ms/step - accuracy: 0.0356 - loss: 0.8332\n",
      "Epoch 3/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 564ms/step - accuracy: 0.0414 - loss: 0.7645\n",
      "Epoch 4/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 590ms/step - accuracy: 0.0486 - loss: 0.6880\n",
      "Epoch 5/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 544ms/step - accuracy: 0.0574 - loss: 0.6077\n",
      "Epoch 6/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 614ms/step - accuracy: 0.0668 - loss: 0.5269\n",
      "Epoch 7/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 559ms/step - accuracy: 0.0772 - loss: 0.4421\n",
      "Epoch 8/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 566ms/step - accuracy: 0.0889 - loss: 0.3593\n",
      "Epoch 9/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 595ms/step - accuracy: 0.1010 - loss: 0.2796\n",
      "Epoch 10/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 613ms/step - accuracy: 0.1112 - loss: 0.2098\n",
      "Epoch 11/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 571ms/step - accuracy: 0.1212 - loss: 0.1533\n",
      "Epoch 12/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 571ms/step - accuracy: 0.1295 - loss: 0.1072\n",
      "Epoch 13/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 549ms/step - accuracy: 0.1345 - loss: 0.0747\n",
      "Epoch 14/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 590ms/step - accuracy: 0.1396 - loss: 0.0551\n",
      "Epoch 15/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 592ms/step - accuracy: 0.1405 - loss: 0.0453\n",
      "Epoch 16/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 575ms/step - accuracy: 0.1416 - loss: 0.0387\n",
      "Epoch 17/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 564ms/step - accuracy: 0.1405 - loss: 0.0368\n",
      "Epoch 18/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 558ms/step - accuracy: 0.1405 - loss: 0.0353\n",
      "Epoch 19/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 540ms/step - accuracy: 0.1422 - loss: 0.0333\n",
      "Epoch 20/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 543ms/step - accuracy: 0.1422 - loss: 0.0286\n",
      "Epoch 21/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 546ms/step - accuracy: 0.1431 - loss: 0.0252\n",
      "Epoch 22/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 570ms/step - accuracy: 0.1438 - loss: 0.0217\n",
      "Epoch 23/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 547ms/step - accuracy: 0.1456 - loss: 0.0199\n",
      "Epoch 24/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 539ms/step - accuracy: 0.1454 - loss: 0.0195\n",
      "Epoch 25/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 580ms/step - accuracy: 0.1463 - loss: 0.0171\n",
      "Epoch 26/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 543ms/step - accuracy: 0.1474 - loss: 0.0157\n",
      "Epoch 27/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 599ms/step - accuracy: 0.1458 - loss: 0.0138\n",
      "Epoch 28/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 551ms/step - accuracy: 0.1465 - loss: 0.0137\n",
      "Epoch 29/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 563ms/step - accuracy: 0.1473 - loss: 0.0123\n",
      "Epoch 30/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 550ms/step - accuracy: 0.1480 - loss: 0.0122\n",
      "Epoch 31/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 574ms/step - accuracy: 0.1476 - loss: 0.0106\n",
      "Epoch 32/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 556ms/step - accuracy: 0.1467 - loss: 0.0100\n",
      "Epoch 33/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 609ms/step - accuracy: 0.1475 - loss: 0.0094\n",
      "Epoch 34/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 574ms/step - accuracy: 0.1480 - loss: 0.0093\n",
      "Epoch 35/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 551ms/step - accuracy: 0.1479 - loss: 0.0086\n",
      "Epoch 36/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 590ms/step - accuracy: 0.1492 - loss: 0.0088\n",
      "Epoch 37/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 633ms/step - accuracy: 0.1485 - loss: 0.0077\n",
      "Epoch 38/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 586ms/step - accuracy: 0.1469 - loss: 0.0068\n",
      "Epoch 39/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 570ms/step - accuracy: 0.1484 - loss: 0.0068\n",
      "Epoch 40/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 578ms/step - accuracy: 0.1486 - loss: 0.0069\n",
      "Epoch 41/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 627ms/step - accuracy: 0.1490 - loss: 0.0061\n",
      "Epoch 42/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 641ms/step - accuracy: 0.1489 - loss: 0.0060\n",
      "Epoch 43/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 542ms/step - accuracy: 0.1488 - loss: 0.0057\n",
      "Epoch 44/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 565ms/step - accuracy: 0.1483 - loss: 0.0061\n",
      "Epoch 45/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 558ms/step - accuracy: 0.1486 - loss: 0.0059\n",
      "Epoch 46/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 546ms/step - accuracy: 0.1492 - loss: 0.0049\n",
      "Epoch 47/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 553ms/step - accuracy: 0.1479 - loss: 0.0051\n",
      "Epoch 48/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 542ms/step - accuracy: 0.1492 - loss: 0.0051\n",
      "Epoch 49/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 615ms/step - accuracy: 0.1483 - loss: 0.0047\n",
      "Epoch 50/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 586ms/step - accuracy: 0.1494 - loss: 0.0049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bb3dd28bf0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# #콜백정의\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss',     # 감시할 값\n",
    "#     patience=3,             # 3 epoch 동안 개선 없으면 멈춤\n",
    "#     restore_best_weights=True,  # 성능 가장 좋았을 때의 가중치 복원\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     filepath='best_model.h5',  # 저장 파일 경로\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True,       # 가장 좋은 성능일 때만 저장\n",
    "#     save_weights_only=True,    # 가중치만 저장\n",
    "#     verbose=1\n",
    "# )\n",
    "# callbacks = [early_stopping, lr_scheduler, checkpoint]\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "x = {\n",
    "    'inputs': questions,\n",
    "    'dec_inputs': answers[:, :-1]\n",
    "}\n",
    "y = answers[:, 1:]\n",
    "\n",
    "model.fit(x, y, batch_size=BATCH_SIZE, epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d848c1a-452c-4fe8-ab29-e1887a14d9a6",
   "metadata": {},
   "source": [
    "# 5. 모델 평가\n",
    "- 데이터 전처리 방법과 inference 단계를 고려하여 decoder_inference() 만들기\n",
    "- decoder_inference() 를 호출하여 대답을 얻는 sentence_generation()함수 만들기\n",
    "- 임의의 문장으로부터 챗봇의 대답을 얻기\n",
    "- 정량적 평가지표 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48876b3c-c7ce-42aa-92cf-e8a656ae02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f281f705-1ffc-4589-b001-43595cc0f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d39feb39-92ce-4cb4-9489-0f1e0bde7bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 너무 우울해\n",
      "출력 : 제 앞에서 울어도 돼요\n",
      "==============================\n",
      "입력 : 시험 망쳤어\n",
      "출력 : 그게 고 싶나봐요\n",
      "==============================\n",
      "입력 : 나 오늘 생일이야\n",
      "출력 : 저도 커피 좋아해요\n",
      "==============================\n",
      "입력 : 친구랑 싸웠어\n",
      "출력 : 싸우면서 정 들 거예요\n",
      "==============================\n",
      "입력 : 날씨가 너무 좋다\n",
      "출력 : 좋은 사람이 찾아오려나봐요\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 사람이 찾아오려나봐요'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#임의의 문장으로부터 챗봇의 대답을 얻어보자\n",
    "sentence_generation(\"오늘 너무 우울해\")\n",
    "print('='*30)\n",
    "sentence_generation(\"시험 망쳤어\")\n",
    "print('='*30)\n",
    "sentence_generation(\"나 오늘 생일이야\")\n",
    "print('='*30)\n",
    "sentence_generation(\"친구랑 싸웠어\")\n",
    "print('='*30)\n",
    "sentence_generation(\"날씨가 너무 좋다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509727f-b564-4522-864e-e5e85be2ded6",
   "metadata": {},
   "source": [
    "- 문법적으로 자연스럽고 사람처럼 표현하지만 가끔 맥락 이해의 한계가 보임\n",
    "- 일부 입력에 대해서는 적절한 공감형 응답 생성, 몇몇 응답은 입력과 무관"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d329c17-2c6e-41d0-bcf4-61aeb14b612b",
   "metadata": {},
   "source": [
    "### 이상적인 답변과 비교해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d69469d3-0e3e-4151-961b-cdcf14c6ad58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 : 혼자 있고 싶어\n",
      "이상적인 응답 : 그럴 땐 혼자만의 시간도 소중하죠.\n",
      "챗봇의 응답 : 혼자만 있지 마세요\n",
      "========================================\n",
      "입력 문장 : 요즘 너무 바빠\n",
      "이상적인 응답 : 무리하지 말고 잠깐 쉬어가는 것도 좋아요.\n",
      "챗봇의 응답 : 하나씩 하세요\n",
      "========================================\n",
      "입력 문장 : 졸려 죽겠어\n",
      "이상적인 응답 : 조금 눈 붙이는 건 어때요?\n",
      "챗봇의 응답 : 사랑에 빠졌나봐요\n",
      "========================================\n",
      "입력 문장 : 누가 나한테 짜증냈어\n",
      "이상적인 응답 : 기분 상했겠어요.\n",
      "챗봇의 응답 : 좋아하는 것을 해보세요\n",
      "========================================\n",
      "입력 문장 : 이번 주말에 뭐하지?\n",
      "이상적인 응답 : 산책이나 영화 보러 가는 건 어때요?\n",
      "챗봇의 응답 : 저랑 이야기해요\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  # print('입력 : {}'.format(sentence))\n",
    "  # print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import pandas as pd\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "smoothie = SmoothingFunction().method4\n",
    "\n",
    "# 입력 문장, 이상적 참조 문장 직접 지정 : 공감, 제안, 위로 등의 일상 대화 스타일\n",
    "custom_data = [\n",
    "    (\"혼자 있고 싶어\", \"그럴 땐 혼자만의 시간도 소중하죠.\"),\n",
    "    (\"요즘 너무 바빠\", \"무리하지 말고 잠깐 쉬어가는 것도 좋아요.\"),\n",
    "    (\"졸려 죽겠어\", \"조금 눈 붙이는 건 어때요?\"),\n",
    "    (\"누가 나한테 짜증냈어\", \"기분 상했겠어요.\"),\n",
    "    (\"이번 주말에 뭐하지?\", \"산책이나 영화 보러 가는 건 어때요?\")\n",
    "]\n",
    "\n",
    "bleu_scores = []\n",
    "\n",
    "for input_text, target_text in custom_data:\n",
    "    predicted_text = sentence_generation(input_text)  # 챗봇 예측값\n",
    "\n",
    "    reference = [target_text.split()]\n",
    "    candidate = predicted_text.split()\n",
    "\n",
    "    bleu = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "    print(f\"입력 문장 : {input_text}\")\n",
    "    print(f\"이상적인 응답 : {target_text}\")\n",
    "    print(f\"챗봇의 응답 : {predicted_text}\")\n",
    "    print(\"=\"*40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a850d-a2f0-4da6-be96-414f3c006af2",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 챗봇 응답의 말투, 스타일, 감정의 결이 조언적이고, 이상적인 답변을 감정적 공감이라고 했을 때 둘의 차이가 확연하게 보였다.\n",
    "- 응답 스타일을 다양하게 시도해보면 좋을 거 같다.\n",
    "- 감정 태깅을 통한 맞춤형 응답 생성\n",
    "  입력 문장에 담긴 감정을 정확히 파악하고 태깅함으로써, 더 적절하고 감정에 공감하는 응답을 생성할 수 있을 것으로 기대된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4e534-2626-4e79-86c3-74bf437e2563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8247d4-3e7f-4174-a20b-81a6b2bb6bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
